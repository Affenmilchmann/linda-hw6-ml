{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "from time import time\n",
    "\n",
    "def mb_size_str(obj: object, name: str):\n",
    "    return f\"{name} size is {round(getsizeof(obj) / pow(1024, 2), 2)}MB\"\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "train_file = \"train.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "INPUT_DATASET_SIZE = train_df.shape[0]\n",
    "b_time = time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changeable configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'TF_IDF': True,\n",
    "    'LEMMATIZE': False,\n",
    "    'DO_STEMMING': False,\n",
    "    'STOPLIST': True,\n",
    "    'LOWFREQ_FILTER': False,\n",
    "    'LOWFREQ_TRESHOLD': 5,\n",
    "    'TEST_RATIO': 0.2, # ratio of train samples that will go as test ones\n",
    "    'MODEL': \"6 Gensim Continuous Skipgram\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:13<00:00, 1857.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#           Preprocessing           #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "import src.preprocessing as prep\n",
    "\n",
    "freq_dict = {}\n",
    "token_amount_counter = [0]\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "    text = train_df.loc[row_id, \"text\"]\n",
    "    train_df.loc[row_id, \"text\"] = prep.preprocess(\n",
    "        text, cfg, freq_dict, token_amount_counter\n",
    "    )\n",
    "\n",
    "if cfg['LOWFREQ_FILTER']:\n",
    "    forms_to_remove = set(w for (w, freq) in freq_dict.items() if freq <= cfg['LOWFREQ_TRESHOLD'])\n",
    "    new_token_amount_counter = [0]\n",
    "    print(f\"Removing low freq tokens (freq <= {cfg['LOWFREQ_TRESHOLD']})...\")\n",
    "    print(f\"Total forms: {len(freq_dict.items())}\")\n",
    "    print(f\"Total forms to be removed {len(forms_to_remove)}\")\n",
    "    for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "        text = train_df.loc[row_id, \"text\"]\n",
    "        train_df.loc[row_id, \"text\"] = prep.remove_lowfreq(text, forms_to_remove, new_token_amount_counter)\n",
    "    shrink_percent = round(100 * (token_amount_counter[0] - new_token_amount_counter[0]) / token_amount_counter[0], 2)\n",
    "    print(f\"Total token amount:\\nold {token_amount_counter[0]}\\nnew {new_token_amount_counter[0]}\\n{shrink_percent}% total less\")\n",
    "\n",
    "train_df.to_csv(f\"train_cleaned.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : TF-IDF matrix...\n",
      "INFO : Матрица на 25000 документов и 144380 термов\n"
     ]
    }
   ],
   "source": [
    "from src.tfidf import get_matrix\n",
    "tfidf, matrix = get_matrix(train_df['text'].to_list()) if cfg['TF_IDF'] else (None, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading projection weights from 6 Gensim Continuous Skipgram/model.bin\n",
      "INFO : KeyedVectors lifecycle event {'msg': 'loaded (302866, 300) matrix of type float32 from 6 Gensim Continuous Skipgram/model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-02-14T22:46:58.793863', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE MODEL\n",
    "from nltk.tokenize import word_tokenize\n",
    "w2v_file = f\"{cfg['MODEL']}/model.bin\"\n",
    "model: gensim.models.keyedvectors.KeyedVectors = gensim.models.KeyedVectors.load_word2vec_format(w2v_file, binary=True)\n",
    "VECTOR_SIZE = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n",
      "Calculating mean review vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:57<00:00, 431.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.vectorizers import get_tfidf_vector\n",
    "\n",
    "def text_vector(text: str, text_id: int) -> np.ndarray:\n",
    "    \"\"\"Compute the normalized weighted mean w2v vector for a given text\"\"\"\n",
    "\n",
    "    tokens = [token for token in word_tokenize(text) if token in model]\n",
    "    # Compute the word2vec vectors for each word in the text\n",
    "    vectors = [model.get_vector(tkn) for tkn in tokens]\n",
    "    if cfg['TF_IDF']:\n",
    "        # Compute the tf-idf values for each word in the text.\n",
    "        tfidf_vals = get_tfidf_vector(tokens, text_id, matrix, tfidf)\n",
    "        # Compute the weighted vectors by multiplying the word2vec vectors by the tf-idf values\n",
    "        weighted_vecs = np.array([vec * factor for vec, factor in zip(vectors, tfidf_vals)])\n",
    "    else:\n",
    "        weighted_vecs = np.array(vectors)\n",
    "\n",
    "    text_sum_vec = np.sum(weighted_vecs, axis=0)\n",
    "    norm_vec = text_sum_vec / np.linalg.norm(text_sum_vec)\n",
    "    \n",
    "    return norm_vec\n",
    "\n",
    "review_vectors = np.empty((INPUT_DATASET_SIZE, VECTOR_SIZE), dtype=float)\n",
    "print(review_vectors.shape)\n",
    "print(\"Calculating mean review vectors...\")\n",
    "for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "    review_vectors[row_id] = text_vector(train_df.loc[row_id, \"text\"], row_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.22057342529297 MB\n"
     ]
    }
   ],
   "source": [
    "# trying not to run out of memory on my potatoe (╥﹏╥)\n",
    "print(getsizeof(review_vectors) / pow(1024, 2), \"MB\")\n",
    "#model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:36<00:00, 159.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# concatenating tfidf and w2v vectors for each text\n",
    "import src.vectorizers as vecs  \n",
    "conc_matrix = vecs.concat_w2v(review_vectors, matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Total answers: 25000\n",
      "    Total reviews: 25000\n",
      "    Review vector size: 144680\n",
      "    Answers splitted: 20000 / 5000\n",
      "    Input splitted: 20000 / 5000\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "answers = train_df['answer'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    conc_matrix,\n",
    "    answers,\n",
    "    test_size=cfg['TEST_RATIO']\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "    Total answers: {answers.shape[0]}\n",
    "    Total reviews: {conc_matrix.shape[0]}\n",
    "    Review vector size: {conc_matrix.shape[1]}\n",
    "    Answers splitted: {y_train.shape[0]} / {y_test.shape[0]}\n",
    "    Input splitted: {X_train.shape[0]} / {X_test.shape[0]}\n",
    "    \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression based on word2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Score on\n",
      "      - train  data : 0.9266\n",
      "      - test   data : 0.877\n",
      "    Test/train size : 0.2\n",
      "    Total time      : 4m 52s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caroline/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pprint import pprint\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "diff = time() - b_time\n",
    "\n",
    "results = {}\n",
    "results.update(cfg)\n",
    "print(f\"\"\"\n",
    "    Score on\n",
    "      - train  data : {reg.score(X_train, y_train)}\n",
    "      - test   data : {reg.score(X_test, y_test)}\n",
    "    Test/train size : {cfg['TEST_RATIO']}\n",
    "    Total time      : {\"{:.0f}m {:.0f}s\".format(*divmod(diff, 60))}\n",
    "\"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      - train  data : 0.83735\n",
    "      - test   data : 0.8364\n",
    "    Test/train size : 0.2\n",
    "\n",
    "    # + tfidf\n",
    "      - train  data : 0.8083555555555556\n",
    "      - test   data : 0.7952\n",
    "    Test/train size : 0.1\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 300 features per sample; expecting 144680",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9g/8skkwnjx0sn_j7_8y5yjwyqc0000gn/T/ipykernel_75422/587168608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_amount_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test_cleaned.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 300 features per sample; expecting 144680"
     ]
    }
   ],
   "source": [
    "def get_vector(text: str) -> np.ndarray:\n",
    "    tokens = [token for token in word_tokenize(text) if token in model]\n",
    "    # Compute the word2vec vectors for each word in the text\n",
    "    vectors = np.array([model.get_vector(tkn) for tkn in tokens])\n",
    "    sum_vector = np.sum(vectors, axis=0)\n",
    "    norm_vector = sum_vector / np.linalg.norm(sum_vector)\n",
    "    return norm_vector\n",
    "\n",
    "test_file = \"test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "TEST_DATASET_SIZE = test_df.shape[0]\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#             Processing            #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "print(\"Processing...\")\n",
    "result = test_df[[\"id\"]].copy()\n",
    "for row_id in tqdm(range(TEST_DATASET_SIZE)):\n",
    "    text = test_df.loc[row_id, \"text\"]\n",
    "    test_df.loc[row_id, \"text\"] = prep.preprocess(\n",
    "        text, cfg, freq_dict, token_amount_counter\n",
    "    )\n",
    "    result.loc[row_id, \"answer\"] = int(reg.predict([get_vector(text)])[0])\n",
    "test_df.to_csv(f\"test_cleaned.csv\", index=False)\n",
    "result[\"answer\"] = result[\"answer\"].astype(int)\n",
    "result.to_csv(f\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 300 features per sample; expecting 144680",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9g/8skkwnjx0sn_j7_8y5yjwyqc0000gn/T/ipykernel_75422/587168608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_amount_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test_cleaned.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 300 features per sample; expecting 144680"
     ]
    }
   ],
   "source": [
    "def get_vector(text: str) -> np.ndarray:\n",
    "    tokens = [token for token in word_tokenize(text) if token in model]\n",
    "    # Compute the word2vec vectors for each word in the text\n",
    "    vectors = np.array([model.get_vector(tkn) for tkn in tokens])\n",
    "    sum_vector = np.sum(vectors, axis=0)\n",
    "    norm_vector = sum_vector / np.linalg.norm(sum_vector)\n",
    "    return norm_vector\n",
    "\n",
    "test_file = \"test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "TEST_DATASET_SIZE = test_df.shape[0]\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#             Processing            #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "print(\"Processing...\")\n",
    "result = test_df[[\"id\"]].copy()\n",
    "for row_id in tqdm(range(TEST_DATASET_SIZE)):\n",
    "    text = test_df.loc[row_id, \"text\"]\n",
    "    test_df.loc[row_id, \"text\"] = prep.preprocess(\n",
    "        text, cfg, freq_dict, token_amount_counter\n",
    "    )\n",
    "    result.loc[row_id, \"answer\"] = int(reg.predict([get_vector(text)])[0])\n",
    "test_df.to_csv(f\"test_cleaned.csv\", index=False)\n",
    "result[\"answer\"] = result[\"answer\"].astype(int)\n",
    "result.to_csv(f\"result.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595442734359384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying bag of words method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### configuring bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  1990  \\\n",
       "0         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "24995     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
       "24996     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "24997     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "24998     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "24999     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "       1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "0         0     0     0     0     0     0     0     0     0  \n",
       "1         0     0     0     0     0     0     0     0     0  \n",
       "2         0     0     0     0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "24995     0     0     0     0     0     0     0     0     0  \n",
       "24996     0     0     0     0     0     0     0     0     0  \n",
       "24997     0     0     0     0     0     0     0     0     0  \n",
       "24998     0     0     0     0     0     0     0     0     0  \n",
       "24999     0     1     0     0     0     0     0     0     0  \n",
       "\n",
       "[25000 rows x 2000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, max_features=2000, stop_words='english')\n",
    "\n",
    "bow = bow_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = bow.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow, x_valid_bow, y_train_bow, y_valid_bow = train_test_split(train_bow,train_df['answer'],test_size=0.3,random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagreg = LogisticRegression(random_state=0,solver='saga', max_iter=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0, solver='saga')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagreg.fit(x_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bow = bagreg.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510743393430478"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_bow[:,1]>=0.3\n",
    "\n",
    "prediction_int = prediction_int.astype(int)\n",
    "\n",
    "log_bow = f1_score(y_valid_bow, prediction_int)\n",
    "\n",
    "log_bow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no change of parameters helped :("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow = XGBClassifier(random_state=0,learning_rate=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.fit(x_train_bow, y_train_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = model_bow.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=xgb[:,1]>=0.3\n",
    "\n",
    "xgb_int=xgb.astype(int)\n",
    "\n",
    "xgb_bow = f1_score(y_valid_bow,xgb_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid_bow, xgb_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dct = DecisionTreeClassifier(criterion='entropy', splitter='random', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1, splitter='random')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.fit(x_train_bow,y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_bow = dct.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714855168748339"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_bow=dct_bow[:,1]>=0.3\n",
    "\n",
    "dct_int_bow=dct_bow.astype(int)\n",
    "\n",
    "dct_score_bow=f1_score(y_valid_bow,dct_int_bow)\n",
    "\n",
    "dct_score_bow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just very bad and I can't help it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = ['logistic regression','XGB','Decision Tree']\n",
    "\n",
    "score_1 = [log_bow,xgb_bow,dct_score_bow]\n",
    "\n",
    "compare_1 = pd.DataFrame({'Model':algs,'F1_Score':score_1},index=[i for i in range(1,4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x='Model',y='F1_Score',data=compare_1, color='pink')\n",
    "\n",
    "plt.title('Bag-of-Words')\n",
    "plt.xlabel('MODEL')\n",
    "plt.ylabel('SCORE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obviously the one with logistic regression is the best one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f16b4f9c118091e521975b08f7e11c780453654917dc239e484e68cca92583fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
