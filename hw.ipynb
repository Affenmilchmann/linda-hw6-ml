{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "from time import time\n",
    "\n",
    "def mb_size_str(obj: object, name: str):\n",
    "    return f\"{name} size is {round(getsizeof(obj) / pow(1024, 2), 2)}MB\"\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "train_file = \"train.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "INPUT_DATASET_SIZE = train_df.shape[0]\n",
    "b_time = time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changeable configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'TF_IDF': True,\n",
    "    'LEMMATIZE': True,\n",
    "    'DO_STEMMING': True,\n",
    "    'STOPLIST': True,\n",
<<<<<<< Updated upstream
    "    'LOWFREQ_FILTER': True,\n",
=======
    "    'LOWFREQ_FILTER': False,\n",
>>>>>>> Stashed changes
    "    'LOWFREQ_TRESHOLD': 5,\n",
    "    'TEST_RATIO': 0.2, # ratio of train samples that will go as test ones\n",
    "    'MODEL': \"6 Gensim Continuous Skipgram\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:37<00:00, 255.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing low freq tokens (freq <= 5)...\n",
      "Total forms: 114739\n",
      "Total forms to be removed 94917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:08<00:00, 2793.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token amount:\n",
      "old 3223418\n",
      "new 3089893\n",
      "4.14% total less\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#           Preprocessing           #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "import src.preprocessing as prep\n",
    "\n",
    "freq_dict = {}\n",
    "token_amount_counter = [0]\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "    text = train_df.loc[row_id, \"text\"]\n",
    "    train_df.loc[row_id, \"text\"] = prep.preprocess(\n",
    "        text, cfg, freq_dict, token_amount_counter\n",
    "    )\n",
    "\n",
    "if cfg['LOWFREQ_FILTER']:\n",
    "    forms_to_remove = set(w for (w, freq) in freq_dict.items() if freq <= cfg['LOWFREQ_TRESHOLD'])\n",
    "    new_token_amount_counter = [0]\n",
    "    print(f\"Removing low freq tokens (freq <= {cfg['LOWFREQ_TRESHOLD']})...\")\n",
    "    print(f\"Total forms: {len(freq_dict.items())}\")\n",
    "    print(f\"Total forms to be removed {len(forms_to_remove)}\")\n",
    "    for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "        text = train_df.loc[row_id, \"text\"]\n",
    "        train_df.loc[row_id, \"text\"] = prep.remove_lowfreq(text, forms_to_remove, new_token_amount_counter)\n",
    "    shrink_percent = round(100 * (token_amount_counter[0] - new_token_amount_counter[0]) / token_amount_counter[0], 2)\n",
    "    print(f\"Total token amount:\\nold {token_amount_counter[0]}\\nnew {new_token_amount_counter[0]}\\n{shrink_percent}% total less\")\n",
    "\n",
    "train_df.to_csv(f\"train_cleaned.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : TF-IDF matrix...\n",
      "INFO : Матрица на 25000 документов и 19671 термов\n"
     ]
    }
   ],
   "source": [
    "from src.tfidf import get_matrix\n",
    "tfidf, matrix = get_matrix(train_df['text'].to_list()) if cfg['TF_IDF'] else (None, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading projection weights from 6 Gensim Continuous Skipgram/model.bin\n",
      "INFO : KeyedVectors lifecycle event {'msg': 'loaded (302866, 300) matrix of type float32 from 6 Gensim Continuous Skipgram/model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-02-14T15:50:46.312795', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE MODEL\n",
    "from nltk.tokenize import word_tokenize\n",
    "w2v_file = f\"{cfg['MODEL']}/model.bin\"\n",
    "model: gensim.models.keyedvectors.KeyedVectors = gensim.models.KeyedVectors.load_word2vec_format(w2v_file, binary=True)\n",
    "VECTOR_SIZE = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n",
      "Calculating mean review vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:47<00:00, 527.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.vectorizers import get_tfidf_vector\n",
    "\n",
    "def text_vector(text: str, text_id: int) -> np.ndarray:\n",
    "    \"\"\"Compute the normalized weighted mean w2v vector for a given text\"\"\"\n",
    "\n",
    "    tokens = [token for token in word_tokenize(text) if token in model]\n",
    "    # Compute the word2vec vectors for each word in the text\n",
    "    vectors = [model.get_vector(tkn) for tkn in tokens]\n",
    "    if cfg['TF_IDF']:\n",
    "        # Compute the tf-idf values for each word in the text.\n",
    "        tfidf_vals = get_tfidf_vector(tokens, text_id, matrix, tfidf)\n",
    "        # Compute the weighted vectors by multiplying the word2vec vectors by the tf-idf values\n",
    "        weighted_vecs = np.array([vec * factor for vec, factor in zip(vectors, tfidf_vals)])\n",
    "    else:\n",
    "        weighted_vecs = np.array(vectors)\n",
    "\n",
    "    text_sum_vec = np.sum(weighted_vecs, axis=0)\n",
    "    norm_vec = text_sum_vec / np.linalg.norm(text_sum_vec)\n",
    "    \n",
    "    return norm_vec\n",
    "\n",
    "review_vectors = np.empty((INPUT_DATASET_SIZE, VECTOR_SIZE), dtype=float)\n",
    "print(review_vectors.shape)\n",
    "print(\"Calculating mean review vectors...\")\n",
    "for row_id in tqdm(range(INPUT_DATASET_SIZE)):\n",
    "    review_vectors[row_id] = text_vector(train_df.loc[row_id, \"text\"], row_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying not to run out of memory on my potatoe (╥﹏╥)\n",
    "print(getsizeof(review_vectors) / pow(1024, 2), \"MB\")\n",
    "#model = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying not to run out of memory on my potatoe (╥﹏╥)\n",
    "print(getsizeof(review_vectors) / pow(1024, 2), \"MB\")\n",
    "#model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating tfidf and w2v vectors for each text\n",
    "import src.vectorizers as vecs  \n",
    "conc_matrix = vecs.concat_w2v(review_vectors, matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
>>>>>>> Stashed changes
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Total answers: 25000\n",
      "    Total reviews: 25000\n",
      "    Review vector size: 300\n",
      "    Answers splitted: 20000 / 5000\n",
      "    Input splitted: 20000 / 5000\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "answers = train_df['answer'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_vectors,\n",
    "    answers,\n",
    "    test_size=cfg['TEST_RATIO']\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "    Total answers: {answers.shape[0]}\n",
    "    Total reviews: {review_vectors.shape[0]}\n",
    "    Review vector size: {review_vectors.shape[1]}\n",
    "    Answers splitted: {y_train.shape[0]} / {y_test.shape[0]}\n",
    "    Input splitted: {X_train.shape[0]} / {X_test.shape[0]}\n",
    "    \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression based on word2vec???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Score on\n",
      "      - train  data : 0.7657\n",
      "      - test   data : 0.7594\n",
      "    Test/train size : 0.2\n",
      "    Total time      : 3m 32s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pprint import pprint\n",
    "\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "diff = time() - b_time\n",
    "\n",
    "results = {}\n",
    "results.update(cfg)\n",
    "print(f\"\"\"\n",
    "    Score on\n",
    "      - train  data : {reg.score(X_train, y_train)}\n",
    "      - test   data : {reg.score(X_test, y_test)}\n",
    "    Test/train size : {cfg['TEST_RATIO']}\n",
    "    Total time      : {\"{:.0f}m {:.0f}s\".format(*divmod(diff, 60))}\n",
<<<<<<< Updated upstream
    "\"\"\")\n"
=======
    "\"\"\")"
>>>>>>> Stashed changes
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      - train  data : 0.83735\n",
    "      - test   data : 0.8364\n",
    "    Test/train size : 0.2\n",
    "\n",
    "    # + tfidf\n",
    "      - train  data : 0.8083555555555556\n",
    "      - test   data : 0.7952\n",
    "    Test/train size : 0.1\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:26<00:00, 171.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_vector(text: str) -> np.ndarray:\n",
    "    tokens = [token for token in word_tokenize(text) if token in model]\n",
    "    # Compute the word2vec vectors for each word in the text\n",
    "    vectors = np.array([model.get_vector(tkn) for tkn in tokens])\n",
    "    sum_vector = np.sum(vectors, axis=0)\n",
    "    norm_vector = sum_vector / np.linalg.norm(sum_vector)\n",
    "    return norm_vector\n",
    "\n",
    "test_file = \"test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "TEST_DATASET_SIZE = test_df.shape[0]\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#             Processing            #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "print(\"Processing...\")\n",
    "result = test_df[[\"id\"]].copy()\n",
    "for row_id in tqdm(range(TEST_DATASET_SIZE)):\n",
    "    text = test_df.loc[row_id, \"text\"]\n",
    "    test_df.loc[row_id, \"text\"] = prep.preprocess(\n",
    "        text, cfg, freq_dict, token_amount_counter\n",
    "    )\n",
    "    result.loc[row_id, \"answer\"] = int(reg.predict([get_vector(text)])[0])\n",
    "test_df.to_csv(f\"test_cleaned.csv\", index=False)\n",
    "result[\"answer\"] = result[\"answer\"].astype(int)\n",
    "result.to_csv(f\"result.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595442734359384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying bag of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### configuring bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  1990  \\\n",
       "0         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "24995     0     0     0     0     0     1     0     0     0     0  ...     0   \n",
       "24996     0     0     0     0     0     0     1     0     0     0  ...     0   \n",
       "24997     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "24998     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "24999     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "       1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "0         0     0     0     0     0     0     0     0     0  \n",
       "1         0     0     0     0     0     0     0     0     0  \n",
       "2         0     0     0     0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "24995     0     0     0     0     0     0     0     0     0  \n",
       "24996     0     0     0     0     0     0     0     0     0  \n",
       "24997     0     0     0     0     0     0     0     0     0  \n",
       "24998     0     0     0     0     0     0     0     0     0  \n",
       "24999     0     0     0     1     0     0     0     0     0  \n",
       "\n",
       "[25000 rows x 2000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, max_features=2000, stop_words='english')\n",
    "\n",
    "bow = bow_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow, x_valid_bow, y_train_bow, y_valid_bow = train_test_split(train_bow,train_df['answer'],test_size=0.3,random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagreg = LogisticRegression(random_state=0,solver='saga', max_iter=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0, solver='saga')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagreg.fit(x_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.94913623e-01, 1.05086377e-01],\n",
       "       [3.14555432e-01, 6.85444568e-01],\n",
       "       [3.79396840e-01, 6.20603160e-01],\n",
       "       ...,\n",
       "       [9.02743008e-01, 9.72569920e-02],\n",
       "       [7.80608419e-05, 9.99921939e-01],\n",
       "       [7.46553343e-02, 9.25344666e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_bow = bagreg.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8561186650185415"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_bow[:,1]>=0.3\n",
    "\n",
    "prediction_int = prediction_int.astype(int)\n",
    "\n",
    "log_bow = f1_score(y_valid_bow, prediction_int)\n",
    "\n",
    "log_bow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no change of parameters helped :("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow = XGBClassifier(random_state=0,learning_rate=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.fit(x_train_bow, y_train_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = model_bow.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370141887723628"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=xgb[:,1]>=0.3\n",
    "\n",
    "xgb_int=xgb.astype(int)\n",
    "\n",
    "f1_score(y_valid_bow,xgb_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8238666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid_bow, xgb_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dct = DecisionTreeClassifier(criterion='entropy', splitter='random', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1, splitter='random')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.fit(x_train_bow,y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_bow = dct.predict_proba(x_valid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7118689223391501"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_bow=dct_bow[:,1]>=0.3\n",
    "\n",
<<<<<<< Updated upstream
    "# converting the results to integer type\n",
    "dct_int_bow=dct_bow.astype(int)\n",
    "\n",
    "# calculating f1 score\n",
=======
    "dct_int_bow=dct_bow.astype(int)\n",
    "\n",
>>>>>>> Stashed changes
    "dct_score_bow=f1_score(y_valid_bow,dct_int_bow)\n",
    "\n",
    "dct_score_bow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just very bad and I can't help it"
   ]
<<<<<<< Updated upstream
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting back to tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(matrix.todense())\n",
    "\n",
    "df_tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = matrix.todense()\n",
    "x_train_tfidf, x_valid_tfidf, y_train_tfidf, y_valid_tfidf = train_test_split(train_matrix, train_df['answer'],test_size=0.3,random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logreg for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_reg = LogisticRegression(random_state=42,solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_reg.fit(x_train_tfidf,y_train_tfidf)\n",
    "\n",
    "prediction_tfidf = tfidf_reg.predict_proba(x_valid_tfidf)\n",
    "\n",
    "prediction_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_int = prediction_tfidf[:,1]>=0.3\n",
    "\n",
    "prediction_int = prediction_int.astype(int)\n",
    "prediction_int\n",
    "\n",
    "log_tfidf = f1_score(y_valid_tfidf, prediction_int)\n",
    "\n",
    "log_tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well, alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f16b4f9c118091e521975b08f7e11c780453654917dc239e484e68cca92583fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
