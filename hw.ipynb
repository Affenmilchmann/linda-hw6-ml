{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "from time import time\n",
    "\n",
    "def mb_size_str(obj: object, name: str):\n",
    "    return f\"{name} size is {round(getsizeof(obj) / pow(1024, 2), 2)}MB\"\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "train_file = \"train.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "INPUT_DATASET_SIZE = train_df.shape[0]\n",
    "b_time = time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'TF_IDF': True,\n",
    "    'LEMMATIZE': False,\n",
    "    'DO_STEMMING': False,\n",
    "    'STOPLIST': True,\n",
    "    'LOWFREQ_FILTER': True,\n",
    "    'LOWFREQ_TRESHOLD': 50,\n",
    "    'TEST_RATIO': 0.2, # ratio of train samples that will go as test ones\n",
    "    'MODEL': \"6 Gensim Continuous Skipgram\",\n",
    "}\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    train_df['text'].to_numpy(),\n",
    "    train_df['answer'].to_numpy(),\n",
    "    test_size=cfg['TEST_RATIO']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:09<00:00, 2083.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1967.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "#           Preprocessing           #\n",
    "# # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "import src.preprocessing as prep\n",
    "\n",
    "freq_dict = {}\n",
    "token_amount_counter_1 = [0]\n",
    "token_amount_counter_2 = [0]\n",
    "\n",
    "print(\"Preprocessing train...\")\n",
    "for i in tqdm(range(len(X_train_raw))):\n",
    "    X_train_raw[i] = prep.preprocess(\n",
    "        X_train_raw[i], cfg, freq_dict, token_amount_counter_1\n",
    "    )\n",
    "\n",
    "print(\"Preprocessing test...\")\n",
    "for i in tqdm(range(len(X_test_raw))):\n",
    "    X_test_raw[i] = prep.preprocess(\n",
    "        X_test_raw[i], cfg, freq_dict, token_amount_counter_2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing low freq tokens (freq <= 50)...\n",
      "Total forms: 144612\n",
      "Total forms to be removed 137870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:01<00:00, 18889.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token amount:\n",
      "old 2410691\n",
      "new 1992046\n",
      "17.37% total less\n",
      "\n",
      "\n",
      "Removing train's low freq tokens from test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 17701.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token amount:\n",
      "old 602770\n",
      "new 497574\n",
      "17.37% total less\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if cfg['LOWFREQ_FILTER']:\n",
    "    forms_to_remove = set(w for (w, freq) in freq_dict.items() if freq <= cfg['LOWFREQ_TRESHOLD'])\n",
    "    new_token_amount_counter = [0]\n",
    "    print(f\"Removing low freq tokens (freq <= {cfg['LOWFREQ_TRESHOLD']})...\")\n",
    "    print(f\"Total forms: {len(freq_dict.items())}\")\n",
    "    print(f\"Total forms to be removed {len(forms_to_remove)}\")\n",
    "    for i in tqdm(range(len(X_train_raw))):\n",
    "        X_train_raw[i] = prep.remove_lowfreq(X_train_raw[i], forms_to_remove, new_token_amount_counter)\n",
    "    shrink_percent = round(100 * (token_amount_counter_1[0] - new_token_amount_counter[0]) / token_amount_counter_1[0], 2)\n",
    "    print(f\"Total token amount:\\nold {token_amount_counter_1[0]}\\nnew {new_token_amount_counter[0]}\\n{shrink_percent}% total less\")\n",
    "\n",
    "    print(f\"\\n\\nRemoving train's low freq tokens from test\")\n",
    "    new_token_amount_counter = [0]\n",
    "    for i in tqdm(range(len(X_test_raw))):\n",
    "        X_test_raw[i] = prep.remove_lowfreq(X_test_raw[i], forms_to_remove, new_token_amount_counter)\n",
    "    print(f\"Total token amount:\\nold {token_amount_counter_2[0]}\\nnew {new_token_amount_counter[0]}\\n{shrink_percent}% total less\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : TF-IDF matrix...\n",
      "INFO : Матрица на 20000 документов и 6542 термов\n"
     ]
    }
   ],
   "source": [
    "from src.tfidf import get_matrix\n",
    "tfidf, matrix = get_matrix(X_train_raw) if cfg['TF_IDF'] else (None, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading projection weights from 6 Gensim Continuous Skipgram/model.bin\n",
      "INFO : KeyedVectors lifecycle event {'msg': 'loaded (302866, 300) matrix of type float32 from 6 Gensim Continuous Skipgram/model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-02-14T23:02:48.130037', 'gensim': '4.3.0', 'python': '3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]', 'platform': 'Linux-6.1.11-1-MANJARO-x86_64-with-glibc2.37', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE MODEL\n",
    "from nltk.tokenize import word_tokenize\n",
    "w2v_file = f\"{cfg['MODEL']}/model.bin\"\n",
    "model: gensim.models.keyedvectors.KeyedVectors = gensim.models.KeyedVectors.load_word2vec_format(w2v_file, binary=True)\n",
    "VECTOR_SIZE = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean review w2v vectors\n",
      "For train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:26<00:00, 744.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 781.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.vectorizers import get_tfidf_vector, mean_w2v_vectors\n",
    "\n",
    "print(\"Calculating mean review w2v vectors\")\n",
    "print(\"For train...\")\n",
    "X_train_w2v = mean_w2v_vectors(tqdm(X_train_raw), model)\n",
    "print(\"For test...\")\n",
    "X_test_w2v = mean_w2v_vectors(tqdm(X_test_raw), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating train's tfidf and w2v vectors for each text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:41<00:00, 476.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming test's tfidf vectors\n",
      "Concatenating test's tfidf and w2v vectors for each text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:09<00:00, 501.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import src.vectorizers as vecs\n",
    "print(\"Concatenating train's tfidf and w2v vectors for each text\")\n",
    "X_train_fullvec = vecs.concat_w2v(X_train_w2v, matrix)\n",
    "\n",
    "print(\"Forming test's tfidf vectors\")\n",
    "tfidf_vecs = tfidf.transform(X_test_raw)\n",
    "print(\"Concatenating test's tfidf and w2v vectors for each text\")\n",
    "X_test_fullvec = vecs.concat_w2v(X_test_w2v, tfidf_vecs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Score on\n",
      "      - train  data : 0.91635\n",
      "      - test   data : 0.8786\n",
      "    Test/train size : 0.2\n",
      "    Total time      : 32m 13s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pprint\n",
    "\n",
    "reg : LogisticRegression = LogisticRegression(max_iter=10_000).fit(X_train_fullvec, y_train)\n",
    "\n",
    "diff = time() - b_time\n",
    "\n",
    "results = {}\n",
    "results.update(cfg)\n",
    "print(f\"\"\"\n",
    "    Score on\n",
    "      - train  data : {reg.score(X_train_fullvec, y_train)}\n",
    "      - test   data : {reg.score(X_test_fullvec, y_test)}\n",
    "    Test/train size : {cfg['TEST_RATIO']}\n",
    "    Total time      : {\"{:.0f}m {:.0f}s\".format(*divmod(diff, 60))}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:06<00:00, 3932.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "X_result_raw = train_df['text'].to_numpy()\n",
    "\n",
    "token_amount_counter_3 = [0]\n",
    "\n",
    "print(\"Preprocessing result...\")\n",
    "for i in tqdm(range(len(X_result_raw))):\n",
    "    X_result_raw[i] = prep.preprocess(\n",
    "        X_result_raw[i], cfg, freq_dict, token_amount_counter_1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Removing train's low freq tokens from result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 20756.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token amount:\n",
      "old 0\n",
      "new 2489620\n",
      "17.37% total less\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\nRemoving train's low freq tokens from result\")\n",
    "new_token_amount_counter = [0]\n",
    "for i in tqdm(range(len(X_result_raw))):\n",
    "    X_result_raw[i] = prep.remove_lowfreq(X_result_raw[i], forms_to_remove, new_token_amount_counter)\n",
    "print(f\"Total token amount:\\nold {token_amount_counter_3[0]}\\nnew {new_token_amount_counter[0]}\\n{shrink_percent}% total less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean review w2v vectors\n",
      "For result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:34<00:00, 715.84it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating mean review w2v vectors\")\n",
    "print(\"For result...\")\n",
    "X_result_w2v = mean_w2v_vectors(tqdm(X_result_raw), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming test's tfidf vectors\n",
      "Concatenating test's tfidf and w2v vectors for each text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:53<00:00, 471.32it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Forming test's tfidf vectors\")\n",
    "tfidf_vecs = tfidf.transform(X_result_raw)\n",
    "print(\"Concatenating test's tfidf and w2v vectors for each text\")\n",
    "X_test_fullvec = vecs.concat_w2v(X_result_w2v, tfidf_vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
